import pyspark
from pyspark import SparkContext
from pyspark.sql import SparkSession
import pandas as pd 
from scipy.stats import skew

from pyspark.conf import SparkConf

spark = SparkSession.builder \
     .appName("Word Count") \
     .master("local[5]") \
     .config("spark.driver.memory","10G")\
     .config('spark.executor.memory',"10G")\
     .config("spark.driver.host", "localhost") \
     .config("spark.driver.maxResultSize","10G")\
     .getOrCreate()
     
sc = spark.sparkContext

###############################################################################
df = spark.read.csv('D:/UNT/Sem 5/data/train.csv/train.csv',header=True,inferSchema =True)
columns_todrop = ["MachineIdentifier","RtpStateBitfield","IsSxsPassiveMode","LocaleEnglishNameIdentifier","OsPlatformSubRelease","OsBuildLab","AutoSampleOptIn","IeVerIdentifier","Census_MDC2FormFactor","Census_DeviceFamily","Census_OEMNameIdentifier","Census_OEMModelIdentifier","Census_PrimaryDiskTotalCapacity","Census_PrimaryDiskTypeName","Census_SystemVolumeTotalCapacity","Census_HasOpticalDiskDrive","Census_TotalPhysicalRAM","Census_ChassisTypeName","Census_InternalPrimaryDiagonalDisplaySizeInInches","Census_InternalPrimaryDisplayResolutionHorizontal","Census_InternalPrimaryDisplayResolutionVertical","Census_PowerPlatformRoleName","Census_InternalBatteryType","Census_InternalBatteryNumberOfCharges","Census_OSInstallLanguageIdentifier","Census_OSUILocaleIdentifier","Census_ThresholdOptIn","Census_FirmwareManufacturerIdentifier","Census_FirmwareVersionIdentifier","Census_IsWIMBootEnabled","Census_IsVirtualDevice","Census_IsTouchEnabled","Census_IsPenCapable","Census_IsAlwaysOnAlwaysConnectedCapable","Wdft_RegionIdentifier"]
df = df.drop(*columns_todrop)
#df.printSchema()
#df.count()
#8921483

###############################################################################
## removing Duplicate values 
df = df.dropDuplicates()
#df.count()
#8911827

###############################################################################
#Removing columns having empty values greater than 80%
from pyspark.sql.functions import isnan, when, count, col
def column_check_nullval(df):
    col_name = []
    value = []
    for i in df.columns:
        val = df.select([count(when(col(str(i)).isNull(),True))])
        val_count = val.toPandas()
        value.append(int(val_count.values))
        col_name.append(str(i))
    return pd.DataFrame({'col_name':col_name,'null_val':value})
        
count_null  = column_check_nullval(df)
count_null.null_val = count_null.null_val/df.count()
count_null.to_csv('D:/UNT/Sem 5/data/train.csv/train_nulls.csv')
count_null=count_null.sort_values(['null_val'],ascending=[False])
columns_null_gt80 =  list(count_null.col_name[count_null.null_val > .80 ])

columns_null_gt80 = ['PuaMode','Census_ProcessorClass','DefaultBrowsersIdentifier','Census_IsFlightingInternal']
df = df.drop(*columns_null_gt80)

############################################################################################
#check for the data skewness and percentage on all variables and remove having high skewness 
#df_new = df.collect()

test = df.select(df.columns).toPandas().skew()

test.to_csv('D:/UNT/Sem 5/data/train.csv/train_skew.csv')

columns_skew_gt10 = ['UacLuaenable','IsBeta','Census_IsFlightsDisabled','Census_IsFlightingInternal','SMode','Census_IsPortableOperatingSystem',
                     'HasTpm']
df = df.drop(*columns_skew_gt10)


df.toPandas().to_csv('D:/UNT/Sem 5/data/train.csv/train_interm_s1.csv',index=False)