# MicrosoftMalware
Predicting weak links in Microsoft systems for malware attacks

## 1.	Title: Microsoft Malware Prediction 

## 2.	Introduction and Statement of the Problem

  •	Now a days detecting malware has been difficult and finding the potential malware has been even more. These malwares are worsening day by day and troubling not only the personal/organization systems but all the cyberspace.

  •	In order to protect the systems for malware and there by finding weak links in system architecture and to secure, this project is taken up.
  
  •	Objective of this project is by applying advance machine learning models to find hidden patterns. Constructing infrastructure to collect data,clean data, build and deploy models.

## 3.	Review of Literature

In this current Internet age malwares like virus ransomware and Trojan horse are serious an alarming security threat to the Internet users, organizations and private users. To protect users from these threat’s anti malware software products from different companies provide a major defense against the malwares. Unfortunately, the number of new malware samples has explosively increased. 

In order to keep on fighting the increase of malware samples there is an important to develop effective methods. An efficient malware detection from the real and large daily sample collection. Following the current trend and one of the most common approaches in literature using machine learning techniques it automatically learns models and patterns behind the complexity and develop functionalities to handle with malware evolution.

This project aims to provide an overview on machine learning models how they can be used in context of malware analysis in windows environment. The objective is to use multiple machine learning models especially tree models to classify the malware prediction using the given data from Kaggle. and initially with the domain knowledge removing multiple features the are insignificant for the analysis and by using statistics inferences removing few more features and thereby filling out empty relations and then training the model with the data to predict the weak link in the system that causes malware. 

## 4.	Objectives of the Study

  To predict a Windows machine’s probability of getting infected by various families of malware, based on different properties of that machine. The telemetry data containing these properties and the machine infections was generated by combining heartbeat and threat reports collected by Microsoft's endpoint protection solution, Windows Defender.
  
## 5.	Data Collection (Give the link to the files, or upload your files if they are not accessible online)
Data acquisition:

Microsoft is providing Kaggle’s with an unprecedented malware dataset to encourage open-source progress on effective techniques for predicting malware occurrences.

Source: https://www.kaggle.com/c/microsoft-malware-prediction/data

## 6.	Exploratory data analysis (EDA) and Hypotheses for the Study

Exploratory data analysis:

Analyzing data set to summarize the main characters. Using correlation, heatmaps doing the feature selections and grouping the observations. Plotting bar plots and histograms trends gives further information on data distributions.

### correlation Plot 1 
  ![Correlation plot 1 ](https://github.com/TRKSasank/MicrosoftMalware/blob/main/Images/Corr%20plot%201.png)
  
### correlation Plot 2
  ![Correlation plot 2 ](https://github.com/TRKSasank/MicrosoftMalware/blob/main/Images/Corr%20plot%202.png)

### correlation Plot 3 
  ![Correlation plot 3 ](https://github.com/TRKSasank/MicrosoftMalware/blob/main/Images/Corr%20plot%203.png)
  

  ![target variable count](https://github.com/TRKSasank/MicrosoftMalware/blob/main/Images/Target%20Count.png)
  
  ![Activation Channel](https://github.com/TRKSasank/MicrosoftMalware/blob/main/Images/Activation%20Channel%20Count.png)
  
  ![Census Edition](https://github.com/TRKSasank/MicrosoftMalware/blob/main/Images/Census%20OS%20Edition.png)
  
  ![Antivirus Sign Version](https://github.com/TRKSasank/MicrosoftMalware/blob/main/Images/AV%20sign%20Version.png)
  
  ![Gamers ](https://github.com/TRKSasank/MicrosoftMalware/blob/main/Images/Gamer.png)
  
  ![Smart Screen Enablement](https://github.com/TRKSasank/MicrosoftMalware/blob/main/Images/Smart%20Screen%20.png)
  
  ![OS Install Type ](https://github.com/TRKSasank/MicrosoftMalware/blob/main/Images/OSInstallType.png)
  
  ![Dashboard](https://github.com/TRKSasank/MicrosoftMalware/blob/main/Images/Final.png)
  
## 7.	Data Analytics

preliminary analysis on data is required by inspecting, transforming and cleaning in process of discovering useful information and derive conclusion on population. 

## Feature Selection:

### Domain Specific insignificant feature removal:

Inspecting each column description in the data source from Kaggle and finding the insignificant features such as Screen size, Disk capacity, Disk type, Physical Ram, Chassis type , Display Resolution, Battery type, Battery charges as not a valid features for causing a weak link for the malware attack. They do not relate to the malware predictions in a software machine.

### Duplicate observation:

Droping the duplicate records from the input data.

### Excluding (NULL) features:

Analyzing the columns with null value percentages more than 70% and removing those specific features from the input data 

### Data Cleaning;

Filling the null values in the rest of the columns with the mean and mode values.

### Skewed Data Excluding:

Excluding the columns which has high skew data , which can tends to bias results 

### Significant features selection and feature matrix building:

Initally With more the 4GB of training data and 83 features then narrowing down to 37 features. Built a sparse matrix, which handle matrix with zeros values called non dense matrix to convert into dense matrix. Using this sparse matrix as input to the machine learning models.

### Analytical models used:

### Random Forest:

Ensemble learning method for classification tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set. Random forests generally outperform decision trees, but their accuracy is lower than gradient boosted trees. However, data characteristics can affect their performance. 

### AdaBoost:

AdaBoost training process selects only those features known to improve the predictive power of the model, reducing dimensionality and potentially improving execution time as irrelevant features don't need to be computed.

### GBC:
It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function.

###  XGBoost:
Salient features of XGBoost which make it different from other gradient boosting algorithms include: 

Clever penalization of trees

Proportional shrinking of leaf nodes

Extra randomization parameter

###  Light Gradient Boost Machine:

It is based on decision tree algorithms and used for ranking, classification and other machine learning tasks. The development focus is on performance and scalability.

Sources: Wikipidea: 
  
## 8.	Data Visualization and Results Report

Upon training the model with 80% of the data and using the rest of the data for the testing for the above-mentioned classifiers below are the metrics, used for evaluation. Like accuracy, logloss, AUC and F-1 Score. 

### Accuracy 

Accuracy shows us how comfortable the model is with detecting the positive and negative class. It's computed by the sum of True Positives and True Negatives divided by the total population. 

Highlighted the models with better results 

RandomForest	  60.48%

AdaBoost 		    62.14%

Gradient Boost	62.59%

**XGBoost 		  64.39%**

**LGBM		      63.80%**

### LogLoss

Log Loss quantifies the accuracy of a classifier by penalizing false classifications. Minimizing the Log Loss is basically equivalent to maximizing the accuracy of the classifier.

To calculate Log Loss the classifier must assign a probability to each class rather than simply yielding the most likely class.

Highlighted the models with better results

Random Forest Log Loss        	    0.6875

Ada Boost Log Loss            		  0.6911

Gradient Boost Log Loss       	    0.6438

**XGBoost Log Loss              		0.6243**

**LGBM Log Loss 			              0.6295**

## AUC (Area under the ROC Curve).

An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds

An ROC curve plots TPR vs. FPR at different classification thresholds. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives. The following figure shows a typical ROC curve.

AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0.
  
Highlighted the models with better results

Random Forest AUC        	0.64

Ada Boost AUC		          0.67

Gradient Boost AUC       	0.67

**XGBoost AUC           	  0.70**

**LGBM AUC			            0.70**

 ![AUC Curve ](https://github.com/TRKSasank/MicrosoftMalware/blob/main/Images/AUC.png)

## F1_score 

The highest possible value of an F-score is 1, indicating perfect precision and recall, and the lowest possible value is 0
 
Highlighted the models with better results

Random Forest 	    0.602

Gradient Boost	    0.622

Ada Boost  	        0.621

**XGBoost Forest 	   0.644**

**LGBoost Forest 	   0.638**
  
## 9.	Conclusion

Form the highlighted model results it is evident that XGboost had an advantage of classifying the weak links for malware attacks.

## 10.	Bibliography

